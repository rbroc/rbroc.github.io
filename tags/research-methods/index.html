<!DOCTYPE html>
<html lang="en-us">
    <head>
        

        <meta charset="utf-8">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <title>research methods</title>
        
        <style>

    html body {
        font-family: 'Montserrat', sans-serif;
        background-color: white;
    }

    :root {
        --accent: #A52A2A;
        --border-width:  5px ;
    }

</style>


<link rel="stylesheet" href="https://rbroc.github.io/css/main.css">





<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Montserrat">


 <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/default.min.css"> 


<link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.4.1/css/bootstrap.min.css" crossorigin="anonymous">


<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css" integrity="sha512-+4zCK9k+qNFUR5X+cKL9EIR+ZOhtIloNl9GIKS57V1MyNsYpYcUrUeQc9vNfzsWfV28IaLL3i96P9sdNyeRssA==" crossorigin="anonymous" />
 

    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js"></script>
    
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/languages/go.min.js"></script>
    
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/languages/haskell.min.js"></script>
    
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/languages/kotlin.min.js"></script>
    
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/languages/scala.min.js"></script>
    
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/languages/swift.min.js"></script>
    
    <script>hljs.initHighlightingOnLoad();</script>






<script src="https://ajax.googleapis.com/ajax/libs/jquery/3.4.1/jquery.min.js"></script>


<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha384-Tc5IQib027qvyjSMfHjOMaLkfuWVxZxUPnCJA7l2mCWNIpG9mGCD8wGNIcPD7Txa" crossorigin="anonymous"></script>


<script>$(document).on('click', function() { $('.collapse').collapse('hide'); })</script>
 <meta name="generator" content="Hugo 0.69.2" />
        
            <link href="/tags/research-methods/index.xml" rel="alternate" type="application/rss&#43;xml" title="Roberta Rocca" />
            <link href="/tags/research-methods/index.xml" rel="feed" type="application/rss&#43;xml" title="Roberta Rocca" />
        

        

        
            <script type="text/javascript" async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
        

        

    </head>

    <body>
        

        <nav class="navbar navbar-default navbar-fixed-top">
            <div class="container">
                <div class="navbar-header">
                    <a class="navbar-brand visible-xs" href="#">research methods</a>
                    <button class="navbar-toggle" data-target=".navbar-collapse" data-toggle="collapse">
                        <span class="icon-bar"></span>
                        <span class="icon-bar"></span>
                        <span class="icon-bar"></span>
                    </button>
                </div>
                <div class="collapse navbar-collapse">
                    
                        <ul class="nav navbar-nav">
                            
                                <li><a href="/">Home</a></li>
                            
                                <li><a href="/about/">About</a></li>
                            
                                <li><a href="/projects/">Projects</a></li>
                            
                                <li><a href="/cv/cv.pdf">Résumé</a></li>
                            
                        </ul>
                    
                    
                        <ul class="nav navbar-nav navbar-right">
                            
                                <li class="navbar-icon"><a href="mailto:rbrrcc@gmail.com"><i class="fas fa-envelope"></i></a></li>
                            
                                <li class="navbar-icon"><a href="https://github.com/rbroc"><i class="fab fa-github"></i></a></li>
                            
                                <li class="navbar-icon"><a href="https://twitter.com/RockBerta/"><i class="fab fa-twitter"></i></a></li>
                            
                                <li class="navbar-icon"><a href="https://www.linkedin.com/in/roberta-rocca-8299a2123/"><i class="fab fa-linkedin"></i></a></li>
                            
                        </ul>
                    
                </div>
            </div>
        </nav>


<main>

    <h2>research methods</h2>

     <div class="item">

    
    
        
        
            
        
    
    

      
    <h4><a href="https://github.com/rbroc/neuroscout-paper/">Neuroscout: a platform for large-scale naturalistic fMRI research</a></h4>
    <h5>At Psychoinformatics Lab, I am contributing to the development of <a href="https://neuroscout.org">Neuroscout</a>, an end-to-end platform for the analysis of naturalistic fMRI data. You can read more about Neuroscout in our eLife paper: <a href="https://elifesciences.org/articles/79277">https://elifesciences.org/articles/79277</a>.
I am focusing on expanding Neuroscout&rsquo;s annotation set by implementing feature extraction pipelines that use pretrained deep learning models (e.g., from HuggingFace&rsquo;s transformers and TensorflowHub) in <a href="https://github.com/PsychoinformaticsLab/pliers">pliers</a>.<br>
I contributed to validating the platform and showing its potential to increase the generalizability of neuroimaging findings through a series of large-scale meta-analyses presented in the paper, and available as a Jupyter book <a href="https://neuroscout.github.io/neuroscout-paper/intro.html">here</a>.</h5>
    
<a href="https://rbroc.github.io/tags/neuroimaging"><kbd class="item-tag">neuroimaging</kbd></a>

<a href="https://rbroc.github.io/tags/research-methods"><kbd class="item-tag">research methods</kbd></a>

<a href="https://rbroc.github.io/tags/machine-learning"><kbd class="item-tag">machine learning</kbd></a>

<a href="https://rbroc.github.io/tags/open-source"><kbd class="item-tag">open-source</kbd></a>



</div>
  <div class="item">

    
    
        
        
            
        
    
    

      
    <h4><a href="https://github.com/rbroc/benchmarks_paper/">Introducing benchmarks for the evaluation of psychological models</a></h4>
    <h5>Quantitative research in psychology and neighboring field emphasizes explanation and in-sample effect sizes over demonstrating models&rsquo; ability to predict on unseen data (generalization).<br>
In a methods paper that interleaves theoretical arguments with empirical demonstrations (code available in <a href="https://github.com/rbroc/benchmarks_paper">this repo</a>), we show how psychology would benefit from adopting benchmarking as a consensus paradigm for model evaluation.<br>
We discuss how psychology can learn from both the strengths and the known weaknesses (e.g., biases, overfitting) of benchmarking in ML, discuss first steps for introducing these new practices in the field, and outline their potential to increase the practical utility of the outputs of psychological research.<br>
This article has been published in <em>Advances in Methods and Practices in Psychological Sciences</em>, and it available at: <a href="https://journals.sagepub.com/doi/full/10.1177/25152459211026864">https://journals.sagepub.com/doi/full/10.1177/25152459211026864</a></h5>
    
<a href="https://rbroc.github.io/tags/research-methods"><kbd class="item-tag">research methods</kbd></a>

<a href="https://rbroc.github.io/tags/evaluation"><kbd class="item-tag">evaluation</kbd></a>

<a href="https://rbroc.github.io/tags/machine-learning"><kbd class="item-tag">machine learning</kbd></a>



</div>
  <div class="item">

    
    
    

      
    <h4><a href="/projects/project7/">The neural underpinnings of spatial demonstratives</a></h4>
    <h5>Spatial demonstratives are words like &lsquo;this&rsquo; and &lsquo;that&rsquo; used to direct manipulate people&rsquo;s attentional focus. They are extremely frequent, yet far from simple. Understanding what they refer to requires not only knowing language, but also the context in which they are pronounced.<br>
As part of my PhD, I ran a naturalistic fMRI study combining synthesized dialogical narratives, fast multiband acquisition, and finite impulse response modeling to understand how the brain makes sense of them.<br>
I found that spatial words engaged dorsal regions of the brain implicated not only in language, but in various aspects of visuospatial cognition, supporting distributed views of language processing.<br>
This study has been published in <em>NeuroImage</em>, and it is available here <a href="https://www.sciencedirect.com/science/article/pii/S1053811919307190">https://www.sciencedirect.com/science/article/pii/S1053811919307190</a></h5>
    
<a href="https://rbroc.github.io/tags/neuroimaging"><kbd class="item-tag">neuroimaging</kbd></a>

<a href="https://rbroc.github.io/tags/language"><kbd class="item-tag">language</kbd></a>

<a href="https://rbroc.github.io/tags/spatial-cognition"><kbd class="item-tag">spatial cognition</kbd></a>

<a href="https://rbroc.github.io/tags/research-methods"><kbd class="item-tag">research methods</kbd></a>



</div>
  <div class="item">

    
    
    

      
    <h4><a href="/projects/project8/">Investigating social modulations of spatial representations through language</a></h4>
    <h5>Humans perceive space as functional to action. Several studies have shown that humans organize space into a peripersonal (i.e., within reach) and an extrapersonal (i.e., outside reach) region.<br>
Interestingly, a lot of the actions we perform in our daily life are performed together with others. Do we adapt the way in which we parse space as near vs. far oto the position of other people when action goals are shared?<br>
We tested this hypothesis over two interactive experiments using language as a proxy for spatial representations.  We found that, in the context of joint action, linguistic coding of locations as proximal vs. distal is based on the position of the partner rather than oneself&rsquo;s.<br>
These studies (part of my PhD) are published in <em>Nature Scientific Reports</em>. The article is available here: <a href="https://www.nature.com/articles/s41598-019-51134-8">https://www.nature.com/articles/s41598-019-51134-8</a></h5>
    
<a href="https://rbroc.github.io/tags/social-cognition"><kbd class="item-tag">social cognition</kbd></a>

<a href="https://rbroc.github.io/tags/language"><kbd class="item-tag">language</kbd></a>

<a href="https://rbroc.github.io/tags/spatial-cognition"><kbd class="item-tag">spatial cognition</kbd></a>

<a href="https://rbroc.github.io/tags/research-methods"><kbd class="item-tag">research methods</kbd></a>



</div>
  <div class="item">

    
    
    

      
    <h4><a href="/projects/project9/">The semantics of spatial demonstratives</a></h4>
    <h5>Spatial demonstratives (words like &lsquo;this&rsquo; and &lsquo;that&rsquo;) are thought to map onto a distinction between near and far space. Yet, when people are asked to pair a noun with a demonstrative without any spatial context, choices tend to be non-random. Over a number of large-scale online experiments, I investigated which semantic features of a referent determine which demonstrative people tend to use to refer to it.<br>
Using PCA and multilevel linear modeling, we found that demonstrative choice is systematically influenced by a range of factors including manipulability, valence, and potential for motion. Importantly, the resulting experimental paradigm (the &lsquo;demonstrative choice task&rsquo;) has been used across a number of languages displaying consistent results, and it is currently being used in follow-up studies to investigate whether linguistic behavior in the demonstrative choice task can be used as predictor of personality and clinical traits.<br>
Studies from my PhD using this paradigm have been published in <a href="https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0210333">PlosOne</a>, <a href="https://www.frontiersin.org/articles/10.3389/fpsyg.2020.00629/full">Frontiers in Psychology</a>, and <a href="https://doi.org/10.1017/langcog.2021.11">Language and Cognition</a>, and two more are currently in progress.</h5>
    
<a href="https://rbroc.github.io/tags/spatial-cognition"><kbd class="item-tag">spatial cognition</kbd></a>

<a href="https://rbroc.github.io/tags/language"><kbd class="item-tag">language</kbd></a>

<a href="https://rbroc.github.io/tags/research-methods"><kbd class="item-tag">research methods</kbd></a>



</div>
 

</main>



        <footer>
            <p class="copyright text-muted">© All rights reserved. Powered by <a href="https://gohugo.io">Hugo</a> and <a href="https://github.com/calintat/minimal">Minimal</a>.</p>
        </footer>

        

        
    </body>

</html>

